{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c54acbeb",
   "metadata": {},
   "source": [
    "# 02c — Calibration & Ablation (Poland, Horizon = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "731c28e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook loaded OK — cells present.\n"
     ]
    }
   ],
   "source": [
    "print('Notebook loaded OK — cells present.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6760b291",
   "metadata": {},
   "source": [
    "**Goals**\n",
    "1. **Calibrate** probabilities (RF: isotonic; Logit: Platt/sigmoid) and re-check Brier + reliability.\n",
    "2. **Ablation:** RF **without** missingness indicators to test robustness.\n",
    "3. Produce **threshold tables** at **1%** and **5%** FPR caps for each model.\n",
    "\n",
    "> Run from repo root so `data/processed/` paths resolve.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f1ac59",
   "metadata": {},
   "source": [
    "### Step 1 — Imports & data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c247c412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes → X_full: (7027, 65) | X_red: (7027, 48) | y pos rate: 0.0386\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss, roc_curve\n",
    "import statsmodels.api as sm\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "REPO_ROOT = Path.cwd()\n",
    "PROC = REPO_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "df_full = pd.read_parquet(PROC / \"poland_clean_full.parquet\")\n",
    "df_red  = pd.read_parquet(PROC / \"poland_clean_reduced.parquet\")\n",
    "\n",
    "full_h1 = df_full[df_full['horizon']==1].copy()\n",
    "red_h1  = df_red[df_red['horizon']==1].copy()\n",
    "\n",
    "y = full_h1['y'].astype(int).values\n",
    "X_full = full_h1.drop(columns=['y','horizon'])\n",
    "X_red  = red_h1.drop(columns=['y','horizon'])\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_STATE)\n",
    "(train_idx, test_idx), = sss.split(X_full, y)\n",
    "\n",
    "Xf_tr, Xf_te = X_full.iloc[train_idx], X_full.iloc[test_idx]\n",
    "Xr_tr, Xr_te = X_red.iloc[train_idx], X_red.iloc[test_idx]\n",
    "y_tr,  y_te  = y[train_idx], y[test_idx]\n",
    "\n",
    "print('Shapes → X_full:', X_full.shape, '| X_red:', X_red.shape, '| y pos rate:', f\"{y.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a70798",
   "metadata": {},
   "source": [
    "### Step 2 — Helpers (metrics, recall@FPR, calibration table, threshold tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18a67268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_fpr(y_true, y_score, fpr_cap=0.01):\n",
    "    fpr, tpr, thr = roc_curve(y_true, y_score)\n",
    "    mask = fpr <= fpr_cap\n",
    "    if not np.any(mask):\n",
    "        return 0.0, None\n",
    "    idx = np.argmax(tpr[mask])\n",
    "    return float(tpr[mask][idx]), float(thr[mask][idx])\n",
    "\n",
    "def calibration_table(y_true, y_prob, n_bins=10):\n",
    "    bins = pd.qcut(y_prob, q=n_bins, duplicates='drop')\n",
    "    tab = pd.DataFrame({'bin': bins, 'y': y_true, 'p': y_prob})\\\n",
    "        .groupby('bin', observed=False).agg(count=('y','size'), mean_pred=('p','mean'), event_rate=('y','mean'))\\\n",
    "        .reset_index()\n",
    "    return tab\n",
    "\n",
    "def evaluate(y_true, y_prob):\n",
    "    return {\n",
    "        'roc': roc_auc_score(y_true, y_prob),\n",
    "        'pr': average_precision_score(y_true, y_prob),\n",
    "        'brier': brier_score_loss(y_true, y_prob),\n",
    "        'rec1': recall_at_fpr(y_true, y_prob, 0.01),\n",
    "        'rec5': recall_at_fpr(y_true, y_prob, 0.05)\n",
    "    }\n",
    "\n",
    "def threshold_summary(y_true, y_score, thr):\n",
    "    yhat = (y_score >= thr).astype(int)\n",
    "    n = len(y_true); pos = int(y_true.sum()); neg = n - pos\n",
    "    tp = int(((yhat==1) & (y_true==1)).sum())\n",
    "    fp = int(((yhat==1) & (y_true==0)).sum())\n",
    "    fn = pos - tp; tn = neg - fp\n",
    "    tpr = tp/pos if pos else 0.0\n",
    "    fpr = fp/neg if neg else 0.0\n",
    "    prec = tp/(tp+fp) if (tp+fp) else 0.0\n",
    "    alerts_per_1000 = 1000*(tp+fp)/n\n",
    "    return {'TP':tp,'FP':fp,'FN':fn,'TN':tn,'TPR':tpr,'FPR':fpr,'Precision':prec,'Alerts_per_1000':alerts_per_1000}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2989509c",
   "metadata": {},
   "source": [
    "### Step 3 — Fit base models (same specs as before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f73007d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base ROC (Logit, RF): 0.924 0.968\n"
     ]
    }
   ],
   "source": [
    "logit = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=True, with_std=True)),\n",
    "    ('clf', LogisticRegression(penalty='l2', solver='liblinear',\n",
    "                               class_weight='balanced', C=1.0, max_iter=200, random_state=RANDOM_STATE))\n",
    "])\n",
    "logit.fit(Xr_tr, y_tr)\n",
    "p_logit = logit.predict_proba(Xr_te)[:,1]\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=400, random_state=RANDOM_STATE,\n",
    "                            class_weight='balanced_subsample', n_jobs=-1,\n",
    "                            max_depth=None, min_samples_leaf=5)\n",
    "rf.fit(Xf_tr, y_tr)\n",
    "p_rf = rf.predict_proba(Xf_te)[:,1]\n",
    "\n",
    "print('Base ROC (Logit, RF):', f\"{roc_auc_score(y_te, p_logit):.3f}\", f\"{roc_auc_score(y_te, p_rf):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8400a5a6",
   "metadata": {},
   "source": [
    "### Step 4 — Calibrate probabilities (Logit=Platt, RF=Isotonic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3d86719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Logit_uncal | ROC=0.924 PR=0.385 Brier=0.1064 | R@1%=0.278 (thr=0.981800) | R@5%=0.648 (thr=0.744987)\n",
      "   Logit_cal | ROC=0.925 PR=0.387 Brier=0.0289 | R@1%=0.296 (thr=0.316068) | R@5%=0.648 (thr=0.085443)\n",
      "    RF_uncal | ROC=0.968 PR=0.738 Brier=0.0208 | R@1%=0.593 (thr=0.311743) | R@5%=0.796 (thr=0.187093)\n",
      "      RF_cal | ROC=0.963 PR=0.738 Brier=0.0178 | R@1%=0.593 (thr=0.296404) | R@5%=0.815 (thr=0.078241)\n"
     ]
    }
   ],
   "source": [
    "# Calibrate Logit (Platt/sigmoid) and RF (isotonic)\n",
    "cal_logit = CalibratedClassifierCV(estimator=logit, method='sigmoid', cv=5)\n",
    "cal_logit.fit(Xr_tr, y_tr)\n",
    "p_logit_cal = cal_logit.predict_proba(Xr_te)[:, 1]\n",
    "\n",
    "cal_rf = CalibratedClassifierCV(estimator=rf, method='isotonic', cv=5)\n",
    "cal_rf.fit(Xf_tr, y_tr)\n",
    "p_rf_cal = cal_rf.predict_proba(Xf_te)[:, 1]\n",
    "\n",
    "# Summaries\n",
    "for name, p in [\n",
    "    ('Logit_uncal', p_logit),\n",
    "    ('Logit_cal',  p_logit_cal),\n",
    "    ('RF_uncal',   p_rf),\n",
    "    ('RF_cal',     p_rf_cal),\n",
    "]:\n",
    "    e = evaluate(y_te, p)\n",
    "    r1, t1 = e['rec1']; r5, t5 = e['rec5']\n",
    "    t1s = 'None' if t1 is None else f'{t1:.6f}'\n",
    "    t5s = 'None' if t5 is None else f'{t5:.6f}'\n",
    "    print(f\"{name:>12} | ROC={e['roc']:.3f} PR={e['pr']:.3f} Brier={e['brier']:.4f} | \"\n",
    "          f\"R@1%={r1:.3f} (thr={t1s}) | R@5%={r5:.3f} (thr={t5s})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b0aba8",
   "metadata": {},
   "source": [
    "## Interpretation (Calibration summaries)\n",
    "\n",
    "* **Logit (Platt):** Massive **calibration** gain (Brier ~0.029). Ranking unchanged (ROC ~0.925), but thresholds now live at sensible ranges (≈0.316 for 1% FPR; ≈0.085 for 5% FPR). Slight lift at 1% FPR recall is nice but limited.\n",
    "* **RF (Isotonic):** Slight AUC trade-off (expected), **better Brier** and **slightly better recall @5% FPR** with similar @1% FPR. Net: **calibration without sacrificing detection**.\n",
    "* **Policy takeaway:** Use **RF_cal** for alerts; keep **Logit_cal/GLM** for interpretable economics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75f0908",
   "metadata": {},
   "source": [
    "### Step 5 — Calibration tables (head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d2c6827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit (uncal) calibration head:\n",
      "                       bin  count  mean_pred  event_rate\n",
      "0  (-0.000999895, 0.0195]    141   0.008294    0.000000\n",
      "1         (0.0195, 0.045]    141   0.031962    0.000000\n",
      "2         (0.045, 0.0767]    140   0.060557    0.000000\n",
      "3         (0.0767, 0.112]    141   0.093760    0.000000\n",
      "4          (0.112, 0.156]    140   0.132571    0.000000\n",
      "5          (0.156, 0.223]    141   0.189368    0.021277\n",
      "6          (0.223, 0.311]    140   0.265087    0.014286\n",
      "7          (0.311, 0.441]    141   0.369789    0.014184\n",
      "8           (0.441, 0.65]    140   0.533753    0.057143\n",
      "9           (0.65, 0.999]    141   0.834228    0.276596\n",
      "\n",
      "Logit (cal) calibration head:\n",
      "                      bin  count  mean_pred  event_rate\n",
      "0  (-0.0009839, 0.00529]    141   0.002976    0.000000\n",
      "1     (0.00529, 0.00856]    141   0.006934    0.000000\n",
      "2      (0.00856, 0.0116]    140   0.010115    0.000000\n",
      "3       (0.0116, 0.0148]    141   0.013177    0.000000\n",
      "4       (0.0148, 0.0183]    140   0.016405    0.000000\n",
      "5       (0.0183, 0.0233]    141   0.020808    0.021277\n",
      "6         (0.0233, 0.03]    140   0.026506    0.014286\n",
      "7         (0.03, 0.0408]    141   0.034864    0.021277\n",
      "8       (0.0408, 0.0656]    140   0.050754    0.050000\n",
      "9        (0.0656, 0.696]    141   0.188269    0.276596\n",
      "\n",
      "RF (uncal) calibration head:\n",
      "                  bin  count  mean_pred  event_rate\n",
      "0  (-0.001, 0.00454]    141   0.002086    0.000000\n",
      "1  (0.00454, 0.0104]    141   0.007476    0.000000\n",
      "2   (0.0104, 0.0171]    140   0.013646    0.000000\n",
      "3   (0.0171, 0.0245]    141   0.020499    0.000000\n",
      "4   (0.0245, 0.0345]    140   0.029951    0.000000\n",
      "5   (0.0345, 0.0503]    141   0.041154    0.000000\n",
      "6    (0.0503, 0.069]    140   0.059211    0.007143\n",
      "7    (0.069, 0.0975]    141   0.081997    0.014184\n",
      "8    (0.0975, 0.153]    140   0.121583    0.042857\n",
      "9       (0.153, 0.9]    141   0.322455    0.319149\n",
      "\n",
      "RF (cal) calibration head:\n",
      "                   bin  count  mean_pred  event_rate\n",
      "0   (-0.001, 0.00182]    425   0.000214    0.000000\n",
      "1  (0.00182, 0.00461]    139   0.002991    0.000000\n",
      "2   (0.00461, 0.0078]    143   0.006370    0.000000\n",
      "3    (0.0078, 0.0123]    138   0.010084    0.000000\n",
      "4      (0.0123, 0.02]    139   0.015590    0.014388\n",
      "5      (0.02, 0.0275]    146   0.023462    0.013699\n",
      "6    (0.0275, 0.0572]    135   0.039216    0.044444\n",
      "7       (0.0572, 1.0]    141   0.297512    0.312057\n"
     ]
    }
   ],
   "source": [
    "print('Logit (uncal) calibration head:\\n', calibration_table(y_te, p_logit).head(10))\n",
    "print('\\nLogit (cal) calibration head:\\n', calibration_table(y_te, p_logit_cal).head(10))\n",
    "print('\\nRF (uncal) calibration head:\\n', calibration_table(y_te, p_rf).head(10))\n",
    "print('\\nRF (cal) calibration head:\\n', calibration_table(y_te, p_rf_cal).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02958c56",
   "metadata": {},
   "source": [
    "## Interpretation (Calibration tables)\n",
    "\n",
    "* **Before calibration**, Logit’s top bin was **wildly overconfident** (mean_pred ~0.83 vs event_rate ~0.28).\n",
    "* **After calibration**, top bin is **much closer** (mean_pred ~0.19 vs 0.28) — underconfident now, but acceptable; we can fine-tune later if needed.\n",
    "* **RF** was already reasonable at the top end; **isotonic** preserves that and improves lower bins’ reliability.\n",
    "* Bottom bins showing ~0% events is expected with such a low base rate and small test fold.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14be009d",
   "metadata": {},
   "source": [
    "### Step 6 — Threshold summaries at exact FPR caps (1% and 5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd66698d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logit_uncal:\n",
      "       cap       thr  TP  FP  FN    TN       TPR       FPR  Precision  \\\n",
      "0  1% FPR  0.981800  15  12  39  1340  0.277778  0.008876   0.555556   \n",
      "1  5% FPR  0.744987  35  63  19  1289  0.648148  0.046598   0.357143   \n",
      "\n",
      "   Alerts_per_1000  \n",
      "0        19.203414  \n",
      "1        69.701280  \n",
      "\n",
      "Logit_cal:\n",
      "       cap       thr  TP  FP  FN    TN       TPR       FPR  Precision  \\\n",
      "0  1% FPR  0.316068  16  12  38  1340  0.296296  0.008876   0.571429   \n",
      "1  5% FPR  0.085443  35  61  19  1291  0.648148  0.045118   0.364583   \n",
      "\n",
      "   Alerts_per_1000  \n",
      "0        19.914651  \n",
      "1        68.278805  \n",
      "\n",
      "RF_uncal:\n",
      "       cap       thr  TP  FP  FN    TN       TPR       FPR  Precision  \\\n",
      "0  1% FPR  0.311743  32  13  22  1339  0.592593  0.009615   0.711111   \n",
      "1  5% FPR  0.187093  43  59  11  1293  0.796296  0.043639   0.421569   \n",
      "\n",
      "   Alerts_per_1000  \n",
      "0         32.00569  \n",
      "1         72.54623  \n",
      "\n",
      "RF_cal:\n",
      "       cap       thr  TP  FP  FN    TN       TPR       FPR  Precision  \\\n",
      "0  1% FPR  0.296404  32   9  22  1343  0.592593  0.006657   0.780488   \n",
      "1  5% FPR  0.078241  44  55  10  1297  0.814815  0.040680   0.444444   \n",
      "\n",
      "   Alerts_per_1000  \n",
      "0        29.160740  \n",
      "1        70.412518  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Logit_uncal':       cap       thr  TP  FP  FN    TN       TPR       FPR  Precision  \\\n",
       " 0  1% FPR  0.981800  15  12  39  1340  0.277778  0.008876   0.555556   \n",
       " 1  5% FPR  0.744987  35  63  19  1289  0.648148  0.046598   0.357143   \n",
       " \n",
       "    Alerts_per_1000  \n",
       " 0        19.203414  \n",
       " 1        69.701280  ,\n",
       " 'Logit_cal':       cap       thr  TP  FP  FN    TN       TPR       FPR  Precision  \\\n",
       " 0  1% FPR  0.316068  16  12  38  1340  0.296296  0.008876   0.571429   \n",
       " 1  5% FPR  0.085443  35  61  19  1291  0.648148  0.045118   0.364583   \n",
       " \n",
       "    Alerts_per_1000  \n",
       " 0        19.914651  \n",
       " 1        68.278805  ,\n",
       " 'RF_uncal':       cap       thr  TP  FP  FN    TN       TPR       FPR  Precision  \\\n",
       " 0  1% FPR  0.311743  32  13  22  1339  0.592593  0.009615   0.711111   \n",
       " 1  5% FPR  0.187093  43  59  11  1293  0.796296  0.043639   0.421569   \n",
       " \n",
       "    Alerts_per_1000  \n",
       " 0         32.00569  \n",
       " 1         72.54623  ,\n",
       " 'RF_cal':       cap       thr  TP  FP  FN    TN       TPR       FPR  Precision  \\\n",
       " 0  1% FPR  0.296404  32   9  22  1343  0.592593  0.006657   0.780488   \n",
       " 1  5% FPR  0.078241  44  55  10  1297  0.814815  0.040680   0.444444   \n",
       " \n",
       "    Alerts_per_1000  \n",
       " 0        29.160740  \n",
       " 1        70.412518  }"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def table_at_caps(name, y_true, y_score):\n",
    "    r1, t1 = recall_at_fpr(y_true, y_score, 0.01)\n",
    "    r5, t5 = recall_at_fpr(y_true, y_score, 0.05)\n",
    "    rows = []\n",
    "    if t1 is not None:\n",
    "        rows.append({'cap':'1% FPR','thr':t1, **threshold_summary(y_true, y_score, t1)})\n",
    "    if t5 is not None:\n",
    "        rows.append({'cap':'5% FPR','thr':t5, **threshold_summary(y_true, y_score, t5)})\n",
    "    return name, pd.DataFrame(rows)\n",
    "\n",
    "tabs = {}\n",
    "for name, p in [('Logit_uncal', p_logit), ('Logit_cal', p_logit_cal),\n",
    "                ('RF_uncal', p_rf), ('RF_cal', p_rf_cal)]:\n",
    "    nm, df = table_at_caps(name, y_te, p)\n",
    "    tabs[nm] = df\n",
    "    print(f\"\\n{name}:\\n\", df)\n",
    "\n",
    "tabs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dbbd45",
   "metadata": {},
   "source": [
    "## Interpretation (Threshold tables @ 1% / 5% FPR)\n",
    "\n",
    "* **RF_cal (recommended):**\n",
    "\n",
    "  * **1% FPR** (thr ≈ **0.2964**): **TP 32, FP 9, FN 22**, Precision ~**0.78**, Alerts **~29/1,000**.\n",
    "    → This is an excellent *strict* early-warning setting.\n",
    "  * **5% FPR** (thr ≈ **0.0782**): **TP 44, FP 55, FN 10**, Precision ~0.44, Alerts **~70/1,000**.\n",
    "    → Use only if stakeholders can tolerate more false alerts to catch ≈**82%** of events.\n",
    "* **Logit_cal** at the same caps catches **fewer TPs** for similar FPs — keep it for interpretation, not as the production detector.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0ce242",
   "metadata": {},
   "source": [
    "### Step 7 — Ablation: RF without missingness indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7382663b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF_noind | ROC=0.938 PR=0.581 Brier=0.0275 | R@1%=0.407 (thr=0.305815) | R@5%=0.704 (thr=0.209867)\n"
     ]
    }
   ],
   "source": [
    "no_ind_cols = [c for c in X_full.columns if not c.endswith('__isna')]\n",
    "Xf_tr_noind = Xf_tr[no_ind_cols]\n",
    "Xf_te_noind = Xf_te[no_ind_cols]\n",
    "\n",
    "rf_noind = RandomForestClassifier(n_estimators=400, random_state=RANDOM_STATE,\n",
    "                                  class_weight='balanced_subsample', n_jobs=-1,\n",
    "                                  max_depth=None, min_samples_leaf=5)\n",
    "rf_noind.fit(Xf_tr_noind, y_tr)\n",
    "p_rf_noind = rf_noind.predict_proba(Xf_te_noind)[:,1]\n",
    "\n",
    "e = evaluate(y_te, p_rf_noind)\n",
    "r1, t1 = e['rec1']; r5, t5 = e['rec5']\n",
    "t1s = 'None' if t1 is None else f'{t1:.6f}'\n",
    "t5s = 'None' if t5 is None else f'{t5:.6f}'\n",
    "print(f\"RF_noind | ROC={e['roc']:.3f} PR={e['pr']:.3f} Brier={e['brier']:.4f} | \"\n",
    "      f\"R@1%={r1:.3f} (thr={t1s}) | R@5%={r5:.3f} (thr={t5s})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e8932e",
   "metadata": {},
   "source": [
    "## Interpretation (Ablation: no `__isna`)\n",
    "\n",
    "* Removing missingness indicators **materially degrades RF** (PR-AUC **0.738 → 0.581**; Recall@1%FPR **0.593 → 0.407**).\n",
    "* Conclusion: **keep the indicators**. They’re legitimate signals (predictors available at decision time), not leakage. We’ll document this explicitly in the report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83931377",
   "metadata": {},
   "source": [
    "### Step 8 — Save calibrated predictions (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15310975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/reebal/FH-Wedel/WS25/seminar-bankruptcy-prediction/data/processed/poland_h1_test_predictions_calibrated.csv\n"
     ]
    }
   ],
   "source": [
    "out = pd.DataFrame({\n",
    "    'y_true': y_te,\n",
    "    'p_logit_uncal': p_logit,\n",
    "    'p_logit_cal': p_logit_cal,\n",
    "    'p_rf_uncal': p_rf,\n",
    "    'p_rf_cal': p_rf_cal,\n",
    "    'p_rf_noind': p_rf_noind\n",
    "})\n",
    "out_path = PROC / 'poland_h1_test_predictions_calibrated.csv'\n",
    "out.to_csv(out_path, index=False)\n",
    "print('Saved:', out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488d3639",
   "metadata": {},
   "source": [
    "## Quick robustness + sanity checks\n",
    "Are indicators just “proxy for the label”? Check their prevalence by class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5852d190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attr21__isna</th>\n",
       "      <th>Attr27__isna</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>non-bankrupt</th>\n",
       "      <td>0.223949</td>\n",
       "      <td>0.028271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bankrupt</th>\n",
       "      <td>0.402214</td>\n",
       "      <td>0.442804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Attr21__isna  Attr27__isna\n",
       "y                                       \n",
       "non-bankrupt      0.223949      0.028271\n",
       "bankrupt          0.402214      0.442804"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_h1[['Attr21__isna','Attr27__isna','y']].groupby('y').mean().rename(index={0:'non-bankrupt',1:'bankrupt'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab972b2",
   "metadata": {},
   "source": [
    "Attr21__isna: 40.2% missing among bankrupt vs 22.4% non-bankrupt\n",
    "\n",
    "Attr27__isna: 44.3% vs 2.8%\n",
    "→ Missingness itself is a strong, valid early-warning signal (as long as those fields are indeed unknown at prediction time, which they are in this dataset)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
