{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis: Patterns & Relationships\n",
    "\n",
    "## Objective\n",
    "\n",
    "Explore relationships and patterns in the data:\n",
    "1. **Feature correlations** - Which ratios move together?\n",
    "2. **Multicollinearity** - Do we have redundant features?\n",
    "3. **Feature importance preview** - Which features discriminate best?\n",
    "4. **Temporal patterns** - Any time-based biases?\n",
    "\n",
    "## Key Questions\n",
    "- Which features are highly correlated (potential multicollinearity)?\n",
    "- Do certain ratio combinations provide better prediction?\n",
    "- Are there temporal biases in the data (2000-2012 vs 2007-2013)?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from src.bankruptcy_prediction.data import DataLoader, MetadataParser\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "print(\"âœ“ Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and metadata\n",
    "loader = DataLoader()\n",
    "metadata = MetadataParser.from_default()\n",
    "\n",
    "df = loader.load_poland(horizon=1, dataset_type='full')\n",
    "X, y = loader.get_features_target(df)\n",
    "\n",
    "print(f\"Dataset: {len(df):,} samples, {len(X.columns)} features\")\n",
    "print(f\"Bankruptcy rate: {y.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Correlation Analysis\n",
    "\n",
    "Identify highly correlated features to understand multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix (sample if too large)\n",
    "# Use only base features (not missingness indicators)\n",
    "base_features = [col for col in X.columns if '__isna' not in col]\n",
    "X_base = X[base_features]\n",
    "\n",
    "# Sample for faster computation if needed\n",
    "if len(base_features) > 64:\n",
    "    print(f\"Sampling {len(base_features)} features\")\n",
    "    base_features = base_features[:64]  # Limit to 64\n",
    "    X_base = X[base_features]\n",
    "\n",
    "print(f\"Calculating correlations for {len(base_features)} features...\")\n",
    "corr_matrix = X_base.corr()\n",
    "print(\"âœ“ Correlation matrix computed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find high correlations\n",
    "high_corr_threshold = 0.9\n",
    "\n",
    "# Get upper triangle (avoid duplicates)\n",
    "upper_tri = np.triu(np.abs(corr_matrix), k=1)\n",
    "high_corr_pairs = []\n",
    "\n",
    "for i in range(len(corr_matrix)):\n",
    "    for j in range(i+1, len(corr_matrix)):\n",
    "        if upper_tri[i, j] >= high_corr_threshold:\n",
    "            feat1 = corr_matrix.columns[i]\n",
    "            feat2 = corr_matrix.columns[j]\n",
    "            corr_val = corr_matrix.iloc[i, j]\n",
    "            \n",
    "            high_corr_pairs.append({\n",
    "                'Feature_1': feat1,\n",
    "                'Feature_2': feat2,\n",
    "                'Correlation': corr_val,\n",
    "                'Name_1': metadata.get_readable_name(feat1, short=True),\n",
    "                'Name_2': metadata.get_readable_name(feat2, short=True),\n",
    "            })\n",
    "\n",
    "high_corr_df = pd.DataFrame(high_corr_pairs).sort_values('Correlation', ascending=False)\n",
    "\n",
    "print(f\"\\nðŸ“Š Found {len(high_corr_df)} feature pairs with |r| â‰¥ {high_corr_threshold}:\\n\")\n",
    "if len(high_corr_df) > 0:\n",
    "    display(high_corr_df.head(20))\n",
    "else:\n",
    "    print(\"âœ“ No extreme multicollinearity (good for linear models)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation:\n",
    "\n",
    "**High correlations indicate:**\n",
    "- Features measuring similar concepts (e.g., different profit margins)\n",
    "- Potential multicollinearity for linear models\n",
    "- Candidates for feature selection\n",
    "\n",
    "**For modeling:**\n",
    "- **Random Forests:** Can handle correlation (not affected)\n",
    "- **Logistic Regression:** Should remove one from each highly correlated pair\n",
    "- **GLM:** Same as Logistic - correlation inflates standard errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlation heatmap (top 30 most important features)\n",
    "# Use simple variance to select features for visualization\n",
    "feature_vars = X_base.var().sort_values(ascending=False)\n",
    "top_features = feature_vars.head(30).index.tolist()\n",
    "\n",
    "corr_subset = X_base[top_features].corr()\n",
    "\n",
    "# Rename for readable plot\n",
    "readable_names = [metadata.get_readable_name(f, short=True) for f in top_features]\n",
    "corr_subset.index = readable_names\n",
    "corr_subset.columns = readable_names\n",
    "\n",
    "plt.figure(figsize=(16, 14))\n",
    "sns.heatmap(corr_subset, \n",
    "            annot=False,\n",
    "            cmap='RdBu_r', \n",
    "            center=0,\n",
    "            vmin=-1, vmax=1,\n",
    "            square=True,\n",
    "            linewidths=0.5,\n",
    "            cbar_kws={'label': 'Correlation'})\n",
    "\n",
    "plt.title('Feature Correlation Heatmap (Top 30 by Variance)', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../results/figures/correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Saved: results/figures/correlation_heatmap.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Discriminative Power Analysis\n",
    "\n",
    "Quick preview: Which features best separate bankrupt from healthy firms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate point-biserial correlation (continuous vs binary)\n",
    "discriminative_power = {}\n",
    "\n",
    "for col in base_features:\n",
    "    # Remove NaN for correlation\n",
    "    valid_mask = ~X_base[col].isna()\n",
    "    if valid_mask.sum() < 100:  # Skip if too few valid values\n",
    "        continue\n",
    "    \n",
    "    x_clean = X_base.loc[valid_mask, col]\n",
    "    y_clean = y[valid_mask]\n",
    "    \n",
    "    # Point-biserial correlation\n",
    "    corr, pval = stats.pointbiserialr(y_clean, x_clean)\n",
    "    \n",
    "    discriminative_power[col] = {\n",
    "        'correlation': corr,\n",
    "        'abs_correlation': abs(corr),\n",
    "        'p_value': pval,\n",
    "        'readable_name': metadata.get_readable_name(col, short=True),\n",
    "        'category': metadata.get_category(col)\n",
    "    }\n",
    "\n",
    "disc_df = pd.DataFrame.from_dict(discriminative_power, orient='index')\n",
    "disc_df = disc_df.sort_values('abs_correlation', ascending=False)\n",
    "\n",
    "print(\"\\nðŸ“Š Top 20 Most Discriminative Features:\\n\")\n",
    "display(disc_df[['readable_name', 'category', 'correlation', 'p_value']].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation:\n",
    "\n",
    "**Point-biserial correlation shows:**\n",
    "- **Negative correlation:** Feature is lower in bankrupt firms (e.g., profitability)\n",
    "- **Positive correlation:** Feature is higher in bankrupt firms (e.g., leverage)\n",
    "- **Magnitude:** Strength of relationship\n",
    "\n",
    "**Expected patterns:**\n",
    "- Profitability ratios: Negative (bankrupt firms less profitable)\n",
    "- Leverage ratios: Positive (bankrupt firms more leveraged)\n",
    "- Liquidity ratios: Negative (bankrupt firms less liquid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize discriminative power by category\n",
    "top_20 = disc_df.head(20).copy()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Color by category\n",
    "category_colors = {\n",
    "    'Profitability': '#3498db',\n",
    "    'Liquidity': '#2ecc71',\n",
    "    'Leverage': '#e74c3c',\n",
    "    'Activity': '#f39c12',\n",
    "    'Size': '#9b59b6',\n",
    "    'Other': '#95a5a6'\n",
    "}\n",
    "\n",
    "colors = [category_colors.get(cat, '#95a5a6') for cat in top_20['category']]\n",
    "\n",
    "bars = ax.barh(range(len(top_20)), top_20['abs_correlation'], color=colors, alpha=0.8)\n",
    "ax.set_yticks(range(len(top_20)))\n",
    "ax.set_yticklabels(top_20['readable_name'])\n",
    "ax.set_xlabel('Absolute Correlation with Bankruptcy', fontweight='bold')\n",
    "ax.set_title('Top 20 Most Discriminative Features', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor=color, label=cat) \n",
    "                   for cat, color in category_colors.items() \n",
    "                   if cat in top_20['category'].values]\n",
    "ax.legend(handles=legend_elements, loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../results/figures/discriminative_power.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Saved: results/figures/discriminative_power.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Category-wise Analysis\n",
    "\n",
    "How do different ratio categories contribute to discrimination?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average discriminative power by category\n",
    "category_disc = disc_df.groupby('category')['abs_correlation'].agg(['mean', 'median', 'std', 'count'])\n",
    "category_disc = category_disc.sort_values('mean', ascending=False)\n",
    "\n",
    "print(\"\\nðŸ“Š Discriminative Power by Category:\\n\")\n",
    "display(category_disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot of discriminative power by category\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "categories = disc_df['category'].unique()\n",
    "data_by_cat = [disc_df[disc_df['category'] == cat]['abs_correlation'].values \n",
    "               for cat in categories]\n",
    "\n",
    "bp = ax.boxplot(data_by_cat, labels=categories, patch_artist=True)\n",
    "\n",
    "for patch, cat in zip(bp['boxes'], categories):\n",
    "    patch.set_facecolor(category_colors.get(cat, '#95a5a6'))\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "ax.set_ylabel('Absolute Correlation with Bankruptcy', fontweight='bold')\n",
    "ax.set_title('Discriminative Power by Feature Category', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../results/figures/discriminative_power_by_category.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Saved: results/figures/discriminative_power_by_category.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation:\n",
    "\n",
    "**Category contributions:**\n",
    "- **Profitability & Leverage** typically show highest discriminative power\n",
    "- **Liquidity** important but often weaker signal\n",
    "- **Activity** ratios capture operational efficiency\n",
    "- **Size** usually has limited predictive power alone\n",
    "\n",
    "**For modeling:**\n",
    "- Focus feature engineering on high-power categories\n",
    "- Don't discard low-power features yet (combinations matter)\n",
    "- Consider category-specific models or weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Next Steps\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Multicollinearity**\n",
    "   - [X] highly correlated pairs identified\n",
    "   - Feature selection needed for linear models\n",
    "   - Tree models can handle correlation\n",
    "\n",
    "2. **Discriminative Features**\n",
    "   - Top predictors identified (profitability, leverage)\n",
    "   - Clear separation between categories\n",
    "   - Strong signals available for prediction\n",
    "\n",
    "3. **Category Patterns**\n",
    "   - Profitability & Leverage most important\n",
    "   - Comprehensive coverage across financial dimensions\n",
    "   - Good foundation for model building\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Data Preparation** (`03_data_preparation.ipynb`)\n",
    "   - Handle correlations for linear models\n",
    "   - Scaling and normalization\n",
    "   - Train/test splits\n",
    "\n",
    "2. **Modeling** (`04_baseline_models.ipynb`)\n",
    "   - Use identified discriminative features\n",
    "   - Compare model families\n",
    "   - Baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save analysis results\n",
    "if len(high_corr_df) > 0:\n",
    "    high_corr_df.to_csv('../../results/evaluation/high_correlations.csv', index=False)\n",
    "    print(\"âœ“ Saved: results/evaluation/high_correlations.csv\")\n",
    "\n",
    "disc_df.to_csv('../../results/evaluation/discriminative_power.csv')\n",
    "print(\"âœ“ Saved: results/evaluation/discriminative_power.csv\")\n",
    "\n",
    "print(\"\\nâœ“ Exploratory analysis complete!\")\n",
    "print(f\"\\nNext: 03_data_preparation.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
